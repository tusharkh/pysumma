{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import os\n",
    "import time\n",
    "import glob\n",
    "import operator\n",
    "import xarray as xr\n",
    "import itertools\n",
    "import summa_plot as sp\n",
    "import pysumma.Simulation\n",
    "import scipy.stats\n",
    "import matplotlib as mpl\n",
    "from pprint import pprint\n",
    "from functools import reduce\n",
    "from scipy.special import psi, inv_boxcox\n",
    "from jupyterthemes import jtplot\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import pandas as pd\n",
    "import importlib\n",
    "from jupyterthemes import jtplot\n",
    "importlib.reload(pysumma.Simulation)\n",
    "\n",
    "jtplot.style('grade3', fscale=1.3)\n",
    "jtplot.figsize(x=18, y=10)\n",
    "mpl.rcParams['figure.figsize'] = (18, 10)\n",
    "\n",
    "MM_PER_M = 1000\n",
    "SEC_PER_MIN = 60\n",
    "MIN_PER_HOUR = 60\n",
    "HOUR_PER_DAY = 24\n",
    "DAY_PER_YEAR = 365\n",
    "# Timestep is 1 hour in our case\n",
    "SEC_PER_TIMESTEP = SEC_PER_MIN * MIN_PER_HOUR\n",
    "\n",
    "user = os.environ['USER']\n",
    "sites = ['Amplero', 'Blodgett', 'Bugac', 'ElSaler', 'ElSaler2', 'Espirra', 'FortPeck', \n",
    "         'Harvard', 'Hesse', 'Howard', 'Howlandm', 'Hyytiala', 'Kruger', 'Loobos', 'Merbleue',\n",
    "         'Mopane', 'Palang', 'Sylvania', 'Tumba', 'UniMich']\n",
    "soil_moisture_sites = ['Amplero', 'Blodgett', 'ElSaler', 'ElSaler2', 'FortPeck', 'Hesse', \n",
    "                       'Hyytiala', 'Loobos', 'Mopane', 'Sylvania']\n",
    "fman_template = \"/pool0/data/\"+user+\"/PLUMBER_data/sites/{}/settings/summa_zFileManager_{}.txt\"\n",
    "oc_template = \"/pool0/data/\"+user+\"/PLUMBER_data/sites/{}/settings/meta/summa_zModelOutput.txt\"\n",
    "fman_dict = {s: fman_template.format(s, s) for s in sites}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "wb_vars = ['pptrate', 'scalarGroundEvaporation', 'scalarCanopyEvaporation',\n",
    "           'scalarSnowSublimation', 'scalarCanopySublimation', 'scalarTotalRunoff', \n",
    "           'scalarSWE', 'scalarTotalSoilLiq',  'scalarTotalSoilIce', \n",
    "           'scalarCanopyIce', 'scalarCanopyLiq', 'scalarCanopyTranspiration', \n",
    "           'scalarLatHeatTotal', 'scalarSenHeatTotal', 'airtemp', 'SWRadAtm']\n",
    "\n",
    "wb_dict = {\n",
    "    'precip': ['pptrate'],\n",
    "    'evap': ['scalarGroundEvaporation', 'scalarCanopyEvaporation', 'scalarCanopyTranspiration', \n",
    "             'scalarSnowSublimation', 'scalarCanopySublimation'],\n",
    "    'runoff': ['scalarTotalRunoff'],\n",
    "    'swe': ['scalarSWE'],\n",
    "    'soil_moisture': ['scalarTotalSoilLiq', 'scalarTotalSoilIce'],\n",
    "    'canopy_moisture': ['scalarCanopyIce', 'scalarCanopyLiq'],\n",
    "    'latent_heat': ['scalarLatHeatTotal'],\n",
    "    'sensible_heat': ['scalarSenHeatTotal'],\n",
    "    'temperature': ['airtemp'],\n",
    "    'shortwave': ['SWRadAtm']\n",
    "}\n",
    "\n",
    "wb_multiplier = {\n",
    "    'precip': SEC_PER_TIMESTEP,\n",
    "    'evap': SEC_PER_TIMESTEP,\n",
    "    'runoff': SEC_PER_TIMESTEP * MM_PER_M,\n",
    "    'swe': 1,\n",
    "    'soil_moisture': 1,\n",
    "    'canopy_moisture': 1,\n",
    "    'latent_heat': -1,\n",
    "    'sensible_heat': -1,\n",
    "    'temperature': 1,\n",
    "    'shortwave': 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def raw_data(data_array):\n",
    "    \"\"\"Unpacks data into a flat array\"\"\"\n",
    "    eps = 1e-12\n",
    "    return data_array.values.flatten() + eps * np.random.random(data_array.shape)\n",
    "\n",
    "\n",
    "def good_inds(x, strict=False):\n",
    "    \"\"\"Remove invalid data\"\"\"\n",
    "    if strict:\n",
    "        return np.where(np.logical_and(x > 1e-10, x < 3000))[0]\n",
    "    return np.where(np.logical_and(x > -3000, x < 3000))[0]\n",
    "\n",
    "def good_data(x, strict=False):\n",
    "    return x[good_inds(x, strict=strict)]\n",
    "\n",
    "def nearest_distances(X, k=1):\n",
    "    \"\"\"Compute distances to kth nearest neighbors\"\"\"\n",
    "    knn = NearestNeighbors(n_neighbors=k, metric='chebyshev')\n",
    "    knn.fit(X)\n",
    "    d, _ = knn.kneighbors(X)\n",
    "    return d[:, -1]\n",
    "\n",
    "\n",
    "def marginal_neighbors(X, R):\n",
    "    \"\"\"Compute number of neighbors in R-radius ball\"\"\"\n",
    "    knn = NearestNeighbors(metric='chebyshev')\n",
    "    knn.fit(X)\n",
    "    return np.array([len(knn.radius_neighbors(p.reshape(1, -1), r)[0][0])\n",
    "                     for p, r in zip(X, R)])\n",
    "\n",
    "\n",
    "def entropy_sk(X, k=False):\n",
    "    \"\"\"Compute entropy H(X1, X2,..., Xn)\"\"\"\n",
    "    try:\n",
    "        n, d = X.shape\n",
    "    except Exception as e:\n",
    "        X = X.reshape(-1, 1)\n",
    "        n, d = X.shape\n",
    "    if not k:\n",
    "        k = 10#int(np.sqrt(n))\n",
    "    eps = 1e-12\n",
    "    r = nearest_distances(X, k) + eps * np.random.random(n)\n",
    "    n, d = X.shape\n",
    "    ent = d * np.log(np.mean(r)) + psi(n) - psi(k) + d * np.log(2)\n",
    "    return ent\n",
    "\n",
    "\n",
    "def mutual_info(x, y, k=False):\n",
    "    \"\"\"Compute I(X; Y)\"\"\"\n",
    "    n = len(x)\n",
    "    if not k:\n",
    "        k = 10#int(np.sqrt(n))\n",
    "    eps = 1e-12\n",
    "    r = nearest_distances(np.array([x, y]).T, k) + eps * np.random.random(n)\n",
    "    n_x = marginal_neighbors(x.reshape(-1,1), r)\n",
    "    n_y = marginal_neighbors(y.reshape(-1,1), r)\n",
    "    psi_x = psi(n_x)\n",
    "    psi_y = psi(n_y)\n",
    "    return (psi(n) + psi(k) - (1./k) - np.mean(psi_x + psi_y))\n",
    "\n",
    "\n",
    "def conditional_mutual_info(X, k=False):\n",
    "    \"\"\"Compute I(X1; X2 | X3:n)\"\"\"\n",
    "    xz = np.array([X[0], *X[2:]]).T\n",
    "    yz = np.array([X[1], *X[2:]]).T\n",
    "    z = np.array(X[2:]).T\n",
    "    d, n = X.shape\n",
    "    if not k:\n",
    "        k = 10\n",
    "    eps = 1e-12\n",
    "    r = nearest_distances(X.T, k) + eps * np.random.random(n)\n",
    "    n_xz = marginal_neighbors(xz, r)\n",
    "    n_yz = marginal_neighbors(yz, r)\n",
    "    n_z = marginal_neighbors(z, r)\n",
    "    psi_xz = psi(n_xz)\n",
    "    psi_yz = psi(n_yz)\n",
    "    psi_z = psi(n_z)\n",
    "    return psi(k) - np.mean(psi_xz + psi_yz - psi_z)\n",
    "    #return (psi(k) - (2./k) - np.mean(-psi_z + psi_xz + psi_yz - (1/n_xz) - (1/n_yz)))\n",
    "\n",
    "def transfer_entropy(X: np.array, lag: int, window: int) -> float:\n",
    "    \"\"\"\n",
    "    Computes TE(X2_t; X1_{t-lag} | X2_{t-lag})\n",
    "\n",
    "    Args:\n",
    "        X: A list containing multiple timeseries.\n",
    "           Example: [evap, precip] will compute\n",
    "           the information transferred from precip to evap,\n",
    "        lag: The time-offset to consider (in timesteps).\n",
    "\n",
    "    Returns:\n",
    "        The value of the equation given above.  Small values\n",
    "        denote less of a connection.  Negative values are\n",
    "        possible, but should be thrown out - as they are\n",
    "        numerical artifacts.\n",
    "    \"\"\"\n",
    "    assert len(X) == 2\n",
    "    # Subsample data and put it together with combination list\n",
    "    sample_size = np.min([5000, len(X[0])-lag-window])\n",
    "    max_start = len(X[0]) - sample_size - lag - window\n",
    "    idx = np.random.choice(np.arange(lag+window, len(X[0])) - lag - window, sample_size)\n",
    "    cmis = []\n",
    "    for w in range(window):\n",
    "        ans = [X[1][idx]]\n",
    "        ans.append(X[0][idx-w-lag])\n",
    "        ans.append(X[1][idx-1])\n",
    "        cmis.append(conditional_mutual_info(np.array(ans)))\n",
    "    return np.sum(cmis)\n",
    "   \n",
    "\n",
    "def conditional_transfer_entropy(X: np.array, lag: int, window: int) -> float:\n",
    "    \"\"\"\n",
    "    Computes TE(X1_t; X2_{t-lag} | X3:n_{t-lag}, X1_{t-lag})\n",
    "\n",
    "    Args:\n",
    "        X: A list containing multiple timeseries.\n",
    "           Example: [evap, precip, runoff] will compute\n",
    "           the information transferred from precip to evap,\n",
    "           eliminating any effects from runoff.\n",
    "        lag: The time-offset to consider (in days).\n",
    "\n",
    "    Returns:\n",
    "        The value of the equation given above.  Small values\n",
    "        denote less of a connection.  Negative values are\n",
    "        possible, but should be thrown out - as they are\n",
    "        numerical artifacts.\n",
    "    \"\"\"\n",
    "    # Need at least 3 variables to compute the TE\n",
    "    assert len(X) > 2\n",
    "    # Subsample data and put it together with combination list\n",
    "    sample_size = np.min([5000, len(X[0])-lag-window])\n",
    "    max_start = len(X[0]) - sample_size - lag - window\n",
    "    idx = np.random.choice(np.arange(lag+window, len(X[0])), sample_size)\n",
    "    cmis = []\n",
    "    for w in range(window):\n",
    "        ans = [X[1][idx]]\n",
    "        ans.append(X[0][idx-w-lag])\n",
    "        for v in X[2:]:\n",
    "            ans.append(v[idx-w-lag])\n",
    "        ans.append(X[1][idx-1])\n",
    "        cmis.append(conditional_mutual_info(np.array(ans)))\n",
    "    return np.sum(cmis)\n",
    "\n",
    "\n",
    "def mutual_info_analysis_full_lagged(ds, out_name, lag=0, window=3, sample_size=3000):\n",
    "    \"\"\"\n",
    "    Compute the mutual information or transfer entropy of variables of\n",
    "    interest for a dataset.  \n",
    "    \"\"\"\n",
    "    precip = raw_data(ds['precip'])\n",
    "    temp = raw_data(ds['temperature'])\n",
    "    soil_moist = raw_data(ds['soil_moisture'])\n",
    "    lat_heat = raw_data(ds['latent_heat'])\n",
    "    sen_heat = raw_data(ds['sensible_heat'])\n",
    "    swrad = raw_data(ds['shortwave'])\n",
    "    \n",
    "    names = ['precipitation', 'temperature', 'soil_moisture', 'latent_heat', 'sensible_heat', 'shortwave']\n",
    "    varlist = [precip, temp, soil_moist, lat_heat, sen_heat, swrad]\n",
    "    good_data = reduce(np.intersect1d, [good_inds(v) for v in varlist])\n",
    "    varlist = np.array([v[good_data] for v in varlist])\n",
    "    \n",
    "    # Compute indices for subsampling\n",
    "    sample_size = np.min([sample_size, len(varlist[0])-lag])\n",
    "    idx = np.random.choice(np.arange(len(varlist[0])-lag), sample_size, replace=False)+lag\n",
    "    \n",
    "    # Calculate all needed variable combinations\n",
    "    mapping = {n: d for n, d in zip(names, varlist)}\n",
    "    permutations = [list(l) for l in list(itertools.permutations(names, 2))]\n",
    "    for combo in permutations:\n",
    "        n = [n for n in names if n not in combo ]\n",
    "        [combo.append(nn) for nn in n]   \n",
    "        \n",
    "    # Subsample data and put it together with combination list\n",
    "    analysis_sets = []\n",
    "    for combo in permutations:\n",
    "        analysis_sets.append([mapping[c] for c in combo])\n",
    "    \n",
    "    # Compute scores\n",
    "    scores = []\n",
    "    for c, s in zip(permutations, analysis_sets):\n",
    "        scores.append(conditional_transfer_entropy(s, lag, window))\n",
    "       \n",
    "    # Reformat into a nice dataframe, save it, and return\n",
    "    df = pd.DataFrame(columns=names, index=names)\n",
    "    for link, score in zip(permutations, scores):\n",
    "        if score < 1e-6:\n",
    "            score = 0\n",
    "        d = {'name_x': link[0], 'name_y': link[1], 'value': score}\n",
    "        df.loc[link[0], link[1]] = score\n",
    "    for name, var in zip(names, varlist):\n",
    "        e_tot = entropy_sk(var[idx])\n",
    "        #print('computing unexplained entropy for {}: {}'.format(name, e_tot))\n",
    "        e_tot -= df[name].sum(skipna=True)\n",
    "        df[name][name] = e_tot\n",
    "    df.to_csv('../data/{}.csv'.format(out_name))\n",
    "    return df\n",
    "\n",
    "def postprocess(ds):\n",
    "    \"\"\"\n",
    "    Aggregate subcomponents and convert units for the\n",
    "    output variables of interest. This also removes\n",
    "    the unnecessary hru dimension\n",
    "    \"\"\"\n",
    "    for k, v in wb_dict.items():\n",
    "        ds[k] = reduce(operator.add, [ds[vv] for vv in v]) * wb_multiplier[k]\n",
    "    ds = ds[list(wb_dict.keys())].isel(hru=0, drop=True)\n",
    "    ds['dswe'] = ds['swe']\n",
    "    ds['dsoil_moisture'] = ds['soil_moisture'].diff(dim='time')\n",
    "    return ds\n",
    "\n",
    "def rmse(da1, da2):\n",
    "    return np.sqrt(np.mean(np.power(da1-da2,2))).values\n",
    "\n",
    "def mbe(da1, da2):\n",
    "    return (np.sum(da1-da2) / len(da1.values)).values\n",
    "\n",
    "def r(da1, da2):\n",
    "    return scipy.stats.pearsonr(da1.values.flatten(),\n",
    "                                da2.values.flatten())[0]\n",
    "\n",
    "def dtw(da1, da2):\n",
    "    return fastdtw(da1.values.flatten(), da2.values.flatten())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_files = []\n",
    "for site in soil_moisture_sites:\n",
    "    out_files += glob.glob('/pool0/data/tushark/PLUMBER_data/sites/' + site + '/summa_output/*output*.nc', recursive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/pool0/data/tushark/PLUMBER_data/sites/Amplero/summa_output/Amplero_output_simplExp_exponential_BallBerry_timestep.nc'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_files[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_name(file):\n",
    "    '''\n",
    "    extracts the combinations from a summa output file\n",
    "    probably could be done much better with a regular\n",
    "    expression\n",
    "    '''\n",
    "    return file.split('summa_output/')[1].split('_timestep.nc')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Amplero_output_difTrans_exponential_Jarvis'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_name(out_files[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutual_info_analysis_combinations(output_file_list):\n",
    "    '''\n",
    "    Takes in a list of summa output files, \n",
    "    runs the mutual input analysis function on them, \n",
    "    and returns a list of the resulting datasets\n",
    "    '''\n",
    "    result = []\n",
    "    for file in output_file_list:\n",
    "        name = get_name(file)\n",
    "        output = postprocess(xr.open_dataset(file))\n",
    "        result.append(mutual_info_analysis_full_lagged(output, name, lag=0, window=10, sample_size=3000))\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/pool0/data/tushark/PLUMBER_data/sites/Amplero/summa_output/Amplero_output_simplExp_exponential_Jarvis_timestep.nc']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_files[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precipitation</th>\n",
       "      <th>temperature</th>\n",
       "      <th>soil_moisture</th>\n",
       "      <th>latent_heat</th>\n",
       "      <th>sensible_heat</th>\n",
       "      <th>shortwave</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precipitation</th>\n",
       "      <td>2.63839</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>temperature</th>\n",
       "      <td>0</td>\n",
       "      <td>3.98626</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00955485</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>soil_moisture</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.57976</td>\n",
       "      <td>0.324351</td>\n",
       "      <td>0.330535</td>\n",
       "      <td>0.241213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latent_heat</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.00875</td>\n",
       "      <td>0.308749</td>\n",
       "      <td>0.383496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sensible_heat</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.480498</td>\n",
       "      <td>5.5569</td>\n",
       "      <td>0.371963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shortwave</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0121631</td>\n",
       "      <td>0</td>\n",
       "      <td>0.74989</td>\n",
       "      <td>0.416495</td>\n",
       "      <td>5.89269</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precipitation temperature soil_moisture latent_heat  \\\n",
       "precipitation       2.63839           0             0           0   \n",
       "temperature               0     3.98626             0           0   \n",
       "soil_moisture             0           0       5.57976    0.324351   \n",
       "latent_heat               0           0             0     5.00875   \n",
       "sensible_heat             0           0             0    0.480498   \n",
       "shortwave                 0   0.0121631             0     0.74989   \n",
       "\n",
       "              sensible_heat shortwave  \n",
       "precipitation             0         0  \n",
       "temperature      0.00955485         0  \n",
       "soil_moisture      0.330535  0.241213  \n",
       "latent_heat        0.308749  0.383496  \n",
       "sensible_heat        5.5569  0.371963  \n",
       "shortwave          0.416495   5.89269  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mutual_info_analysis_combinations(out_files[0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "result1 = mutual_info_analysis_combinations(out_files[1:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "result2 = mutual_info_analysis_combinations(out_files[2:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result3 = mutual_info_analysis_combinations(out_files[3:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "result4 = mutual_info_analysis_combinations(out_files[30:40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "result5 = mutual_info_analysis_combinations(out_files[40:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "default"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
